{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "\n",
    "    def __init__(self, weights_cnt):\n",
    "\n",
    "        self._weights = np.random.uniform(-1, 1, weights_cnt)\n",
    "        self._bias = np.random.uniform(-1, 1)\n",
    "        self._out = 0\n",
    "        self._sum = 0           \n",
    "\n",
    "\n",
    "    def __ReLU(self):\n",
    "        return max(0, self._sum)\n",
    "    \n",
    "\n",
    "    def __tanh(self):\n",
    "        return 2 / (1 + np.exp(-2 * self._sum)) - 1\n",
    "    \n",
    "\n",
    "    def __Softmax(self):\n",
    "        exps = np.exp(self._sum)\n",
    "        return exps / exps.sum()\n",
    "    \n",
    "\n",
    "    def __Sigmoid(self):\n",
    "        return 1 / (1 + np.exp(-self._sum))\n",
    "    \n",
    "\n",
    "    def __deriv_Sigmoid(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "\n",
    "    def forward(self, input, fun_activ):\n",
    "\n",
    "        self._sum = np.dot(input, self._weights) + self._bias\n",
    "\n",
    "        if fun_activ == 'ReLU':\n",
    "            self._out = self.__ReLU()\n",
    "        \n",
    "        elif fun_activ == 'tanh':\n",
    "            self._out = self.__tanh()\n",
    "        \n",
    "        elif fun_activ == 'Softmax':\n",
    "            self._out = self.__Softmax()\n",
    "        \n",
    "        elif fun_activ == 'Sigmoid':\n",
    "            self._out = self.__Sigmoid()\n",
    "        \n",
    "        return self._out\n",
    "        \n",
    "    @property\n",
    "    def backward(self):\n",
    "        out = self.__Sigmoid()        \n",
    "        return self.__deriv_Sigmoid(out)\n",
    "\n",
    "\n",
    "    def update_weights(self, val):\n",
    "        self._weights += val\n",
    "\n",
    "\n",
    "    def update_bias(self, val):\n",
    "        self._bias += val\n",
    "\n",
    "\n",
    "    @property\n",
    "    def get_weights(self):\n",
    "        return self._weights\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def get_bias(self):\n",
    "        return self._bias\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def get_out(self):\n",
    "        return self._out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, layers_cnt, cnt_in_layers, funs_activ):\n",
    "        \n",
    "        self._layers = [([Neuron(cnt_in_layers[i - 1]) for _ in range(cnt_in_layers[i])], funs_activ[i - 1]) for i in range(1, layers_cnt)]\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        for (layer, fun_activ) in self._layers:\n",
    "            \n",
    "            new_input = []\n",
    "\n",
    "            for neuron in layer:\n",
    "                new_input.append(neuron.forward(input, fun_activ))\n",
    "\n",
    "            input = new_input\n",
    "\n",
    "        return input[0]\n",
    "    \n",
    "\n",
    "    def backward(self, input, loss, learn_rate):\n",
    "\n",
    "        h1 = self._layers[0][0][0]\n",
    "        h2 = self._layers[0][0][1]\n",
    "        o1 = self._layers[1][0][0]\n",
    "\n",
    "        d_w1_h1 = loss * o1.backward * o1.get_weights[0] * h1.backward * input[0]\n",
    "        d_w2_h1 = loss * o1.backward * o1.get_weights[0] * h1.backward * input[1]\n",
    "        d_b_h1 = loss * o1.backward * o1.get_weights[0] * h1.backward\n",
    "\n",
    "        d_w1_h2 = loss * o1.backward * o1.get_weights[1] * h2.backward * input[0]\n",
    "        d_w2_h2 = loss * o1.backward * o1.get_weights[1] * h2.backward * input[1]\n",
    "        d_b_h2 = loss * o1.backward * o1.get_weights[1] * h2.backward\n",
    "\n",
    "        d_w1_o1 = loss * o1.backward * h1.get_out\n",
    "        d_w2_o1 = loss * o1.backward * h2.get_out\n",
    "        d_b_o1 = loss * o1.backward\n",
    "\n",
    "        h1.update_weights([d_w1_h1 * learn_rate, d_w2_h1 * learn_rate])\n",
    "        h2.update_weights([d_w1_h2 * learn_rate, d_w2_h2 * learn_rate])\n",
    "        o1.update_weights([d_w1_o1 * learn_rate, d_w2_o1 * learn_rate])\n",
    "\n",
    "        h1.update_bias(d_b_h1 * learn_rate)\n",
    "        h2.update_bias(d_b_h2 * learn_rate)\n",
    "        o1.update_bias(d_b_o1 * learn_rate)\n",
    "        \n",
    "\n",
    "    def train(self, train_x, train_y, epochs, learn_rate):\n",
    "\n",
    "        for i in range(epochs):\n",
    "  \n",
    "            id = i % len(train_x)\n",
    "\n",
    "            y_pred = self.forward(train_x[id])\n",
    "            self.backward(train_x[id], train_y[id] - y_pred, learn_rate)\n",
    "\n",
    "\n",
    "    def predict(self, input):\n",
    "\n",
    "        if self.forward(input) >= 0.5:\n",
    "            return 1\n",
    "\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanya\\AppData\\Local\\Temp\\ipykernel_15084\\2881701384.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * self._sum)) - 1\n"
     ]
    }
   ],
   "source": [
    "net = Model(5, [256, 64, 16, 4, 1], ['ReLU', 'tanh', 'tanh', 'Softmax'])\n",
    "print(net.forward(np.random.randint(-100, 100, 256)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "\n",
    "    def convolution2D(self, input, kernel):\n",
    "        \n",
    "        out_rows_cnt = len(input) - len(kernel) + 1\n",
    "        out_colms_cnt = len(input[0]) - len(kernel[0]) + 1\n",
    "        kernel_rows_cnt = len(kernel)\n",
    "        kernel_colms_cnt = len(kernel[0])\n",
    "\n",
    "        res = np.zeros((out_rows_cnt, out_colms_cnt))\n",
    "\n",
    "        for i in range(out_rows_cnt):\n",
    "            for j in range(out_colms_cnt):\n",
    "\n",
    "                sum = 0\n",
    "\n",
    "                for u in range(kernel_rows_cnt):\n",
    "                    for v in range(kernel_colms_cnt):\n",
    "\n",
    "                        sum += input[i + u][j + v] * kernel[u][v]\n",
    "\n",
    "                res[i][j] = sum\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "    def convolution_n_channels(self, input, output_size):\n",
    "\n",
    "        rows_cnt = len(input)\n",
    "        colms_cnt = len(input[0])\n",
    "        channels_cnt = len(input[0][0])\n",
    "\n",
    "        res_channel = np.zeros(output_size)\n",
    "\n",
    "        for channel in range(channels_cnt):\n",
    "            \n",
    "            kernel = np.random.uniform(-1, 1, (rows_cnt - output_size[0] + 1 , colms_cnt - output_size[1] + 1))\n",
    "            cur_channel = []\n",
    "\n",
    "            for n in range(rows_cnt):\n",
    "                for m in range(colms_cnt):\n",
    "                    cur_channel.append(input[n][m][channel])\n",
    "\n",
    "            cur_channel = np.array(cur_channel).reshape(rows_cnt, colms_cnt)\n",
    "            cur_channel = self.convolution2D(cur_channel, kernel)\n",
    "\n",
    "            res_channel += cur_channel\n",
    "\n",
    "        return res_channel\n",
    "    \n",
    "\n",
    "    def convUp_to_n_channels(self, input, output_size):\n",
    "        \n",
    "        conv_cnt = output_size[2]\n",
    "\n",
    "        res = []\n",
    "\n",
    "        for i in range(conv_cnt):\n",
    "\n",
    "            new_channel = self.convolution_n_channels(input, (output_size[0], output_size[1]))\n",
    "            new_channel = new_channel.ravel()\n",
    "\n",
    "            for a in range(len(new_channel)):\n",
    "                res = np.insert(res, i + a * (i + 1), max(new_channel[a], 0)) #Составление результирующей матрицы с использованием ReLU\n",
    "\n",
    "        return res.reshape(output_size)\n",
    "\n",
    "\n",
    "    def maxPool(self, input, output_size):\n",
    "         \n",
    "        rows_cnt = len(input)\n",
    "        colms_cnt = len(input[0])\n",
    "        channels_cnt = len(input[0][0])\n",
    "\n",
    "        out_w = output_size[0]\n",
    "        out_h = output_size[1]\n",
    "        ker_w = input.shape[0] // out_w\n",
    "        ker_h = input.shape[1] // out_h\n",
    "\n",
    "        res_mtx = []\n",
    "\n",
    "        for channel in range(channels_cnt):\n",
    "         \n",
    "            cur_channel = []\n",
    "\n",
    "            for n in range(rows_cnt):\n",
    "                for m in range(colms_cnt):\n",
    "                    cur_channel.append(input[n][m][channel])\n",
    "\n",
    "            cur_channel = np.array(cur_channel).reshape(rows_cnt, colms_cnt)\n",
    "            cur_channel = cur_channel[:out_w * ker_w, :out_h * ker_h].reshape(out_w, ker_w, out_h, ker_h).max(axis = (1, 3))\n",
    "\n",
    "            for a in range(len(cur_channel)):\n",
    "                res_mtx = np.insert(res_mtx, channel + a * (channel + 1), cur_channel[a])\n",
    "\n",
    "        return res_mtx.reshape(output_size)\n",
    "\n",
    "\n",
    "    def make_conv_pass(self, img, seq):\n",
    "\n",
    "        for i in range(0, len(seq) - 1, 2):\n",
    "            img = self.convUp_to_n_channels(img, seq[i])\n",
    "            img = self.maxPool(img, seq[i + 1])\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 16)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.randint(0, 256, (19, 19, 3))\n",
    "sequence = [(18, 18, 8), (9, 9, 8), (8, 8, 16), (4, 4, 16)]\n",
    "\n",
    "conv_net = CNN()\n",
    "img = conv_net.make_conv_pass(img, sequence)\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanya\\AppData\\Local\\Temp\\ipykernel_15084\\2881701384.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * self._sum)) - 1\n"
     ]
    }
   ],
   "source": [
    "img = np.random.randint(0, 256, (19, 19, 3))\n",
    "sequence = [(18, 18, 8), (9, 9, 8), (8, 8, 16), (4, 4, 16), (2, 2, 32), (1, 1, 32)]\n",
    "net = Model(5, [32, 16, 8, 4, 1], ['ReLU', 'tanh', 'tanh', 'Softmax'])\n",
    "\n",
    "img = conv_net.make_conv_pass(img, sequence)\n",
    "\n",
    "print(net.forward(img.ravel()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (2,) doesn't match the broadcast shape (2,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sanya\\Desktop\\ПАК\\10\\10.ipynb Cell 12\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xor \u001b[39m=\u001b[39m Model(\u001b[39m3\u001b[39m, [\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m'\u001b[39m\u001b[39mSigmoid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSigmoid\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m xor\u001b[39m.\u001b[39;49mtrain(train_x \u001b[39m=\u001b[39;49m np\u001b[39m.\u001b[39;49marray([[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m], [\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m], [\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m], [\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m]]), train_y \u001b[39m=\u001b[39;49m np\u001b[39m.\u001b[39;49marray([\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m]), epochs \u001b[39m=\u001b[39;49m \u001b[39m50000\u001b[39;49m, learn_rate \u001b[39m=\u001b[39;49m \u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(xor\u001b[39m.\u001b[39mpredict([\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(xor\u001b[39m.\u001b[39mpredict([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]))\n",
      "\u001b[1;32mc:\\Users\\Sanya\\Desktop\\ПАК\\10\\10.ipynb Cell 12\u001b[0m in \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m i \u001b[39m%\u001b[39m \u001b[39mlen\u001b[39m(train_x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(train_x[\u001b[39mid\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackward(train_x[\u001b[39mid\u001b[39;49m], train_y[\u001b[39mid\u001b[39;49m] \u001b[39m-\u001b[39;49m y_pred, learn_rate)\n",
      "\u001b[1;32mc:\\Users\\Sanya\\Desktop\\ПАК\\10\\10.ipynb Cell 12\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m d_w2_o1 \u001b[39m=\u001b[39m loss \u001b[39m*\u001b[39m o1\u001b[39m.\u001b[39mbackward \u001b[39m*\u001b[39m h2\u001b[39m.\u001b[39mget_out\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m d_b_o1 \u001b[39m=\u001b[39m loss \u001b[39m*\u001b[39m o1\u001b[39m.\u001b[39mbackward\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m h1\u001b[39m.\u001b[39;49mupdate_weights([d_w1_h1 \u001b[39m*\u001b[39;49m learn_rate, d_w2_h1 \u001b[39m*\u001b[39;49m learn_rate])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m h2\u001b[39m.\u001b[39mupdate_weights([d_w1_h2 \u001b[39m*\u001b[39m learn_rate, d_w2_h2 \u001b[39m*\u001b[39m learn_rate])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m o1\u001b[39m.\u001b[39mupdate_weights([d_w1_o1 \u001b[39m*\u001b[39m learn_rate, d_w2_o1 \u001b[39m*\u001b[39m learn_rate])\n",
      "\u001b[1;32mc:\\Users\\Sanya\\Desktop\\ПАК\\10\\10.ipynb Cell 12\u001b[0m in \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_weights\u001b[39m(\u001b[39mself\u001b[39m, val):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sanya/Desktop/%D0%9F%D0%90%D0%9A/10/10.ipynb#X14sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weights \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m val\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (2,) doesn't match the broadcast shape (2,2)"
     ]
    }
   ],
   "source": [
    "xor = Model(3, [2, 2, 1], ['Sigmoid', 'Sigmoid'])\n",
    "xor.train(train_x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]), train_y = np.array([0, 1, 1, 0]), epochs = 50000, learn_rate = 0.1)\n",
    "\n",
    "print(xor.predict([0, 0]))\n",
    "print(xor.predict([0, 1]))\n",
    "print(xor.predict([1, 0]))\n",
    "print(xor.predict([1, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af874b8d4f4459788df716e07a9b2cbb6aef8352bcd428451245bb55fab53f6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
